{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T18:23:14.399689Z",
     "start_time": "2020-08-07T18:23:11.680976Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T18:35:51.169154Z",
     "start_time": "2020-08-07T18:35:51.120465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 4.96, b 1.44, iteration 0, cost 89.0\n",
      "m 0.4991999999999983, b 0.26879999999999993, iteration 1, cost 71.10560000000002\n",
      "m 4.451584000000002, b 1.426176000000001, iteration 2, cost 56.8297702400001\n",
      "m 0.892231679999997, b 0.5012275199999995, iteration 3, cost 45.43965675929613\n",
      "m 4.041314713600002, b 1.432759910400001, iteration 4, cost 36.35088701894832\n",
      "m 1.2008760606719973, b 0.7036872622079998, iteration 5, cost 29.097483330142282\n",
      "m 3.7095643080294423, b 1.4546767911321612, iteration 6, cost 23.307872849944438\n",
      "m 1.4424862661541864, b 0.881337636696883, iteration 7, cost 18.685758762535738\n",
      "m 3.4406683721083144, b 1.4879302070713722, iteration 8, cost 14.994867596913156\n",
      "m 1.6308855378034224, b 1.0383405553279617, iteration 9, cost 12.046787238456794\n",
      "m 3.2221235247119777, b 1.5293810083298451, iteration 10, cost 9.691269350698109\n",
      "m 1.7770832372205707, b 1.1780607551353204, iteration 11, cost 7.8084968312098315\n",
      "m 3.0439475772474127, b 1.5765710804477953, iteration 12, cost 6.302918117062937\n",
      "m 1.8898457226770244, b 1.3032248704973899, iteration 13, cost 5.098330841763168\n",
      "m 2.898169312926714, b 1.6275829443328358, iteration 14, cost 4.133961682056365\n",
      "m 1.9761515088959358, b 1.4160484030347593, iteration 15, cost 3.361340532576948\n",
      "m 2.7784216197824048, b 1.6809279342791488, iteration 16, cost 2.741808050753047\n",
      "m 2.0415541605113807, b 1.5183370872989306, iteration 17, cost 2.244528230107478\n",
      "m 2.6796170361078637, b 1.735457156285639, iteration 18, cost 1.8449036666988363\n",
      "m 2.090471617540917, b 1.611567833948162, iteration 19, cost 1.5233119201782324\n",
      "m 2.5976890103737853, b 1.790290604096816, iteration 20, cost 1.2640979056612756\n",
      "m 2.1264168621494517, b 1.6969533824619085, iteration 21, cost 1.0547704368105268\n",
      "m 2.529385561184701, b 1.8447607474362664, iteration 22, cost 0.8853615531285766\n",
      "m 2.1521818147302194, b 1.7754939584778073, iteration 23, cost 0.7479156468369821\n",
      "m 2.472104720735685, b 1.8983676540508527, iteration 24, cost 0.6360820885229722\n",
      "m 2.1699839382964696, b 1.8480185634495874, iteration 25, cost 0.5447903801652151\n",
      "m 2.423763296438881, b 1.950743302915348, iteration 26, cost 0.4699911136477278\n",
      "m 2.1815831093070837, b 1.9152179921582295, iteration 27, cost 0.4084494012702221\n",
      "m 2.3826922006906663, b 2.0016232209455125, iteration 28, cost 0.35758014655339476\n",
      "m 2.1883747814212473, b 1.9776712492627107, iteration 29, cost 0.31531667795040486\n",
      "m 2.3475529664737507, b 2.0508239542984783, iteration 30, cost 0.280005985849834\n",
      "m 2.19146424741668, b 2.0358666977033213, iteration 31, cost 0.2503251729489924\n",
      "m 2.317271157065729, b 2.0982251873107836, iteration 32, cost 0.2252148202231392\n",
      "m 2.19172583072087, b 2.0902190019495084, iteration 33, cost 0.2038258415569305\n",
      "m 2.2909832477163747, b 2.1437555628915694, iteration 34, cost 0.1854770944836773\n",
      "m 2.1898500615476015, b 2.1410827139250586, iteration 35, cost 0.16962156815305135\n",
      "m 2.2679942505397945, b 2.1873814501542004, iteration 36, cost 0.15581941113049289\n",
      "m 2.1863812735157397, b 2.188763177870427, iteration 37, cost 0.14371641365577967\n",
      "m 2.247743906750233, b 2.2290980581236037, iteration 38, cost 0.13302683968149862\n",
      "m 2.181747562970493, b 2.2335252935837153, iteration 39, cost 0.1235197278285518\n",
      "m 2.2297797112222417, b 2.268922416384484, iteration 40, cost 0.11500795886067308\n",
      "m 2.176284659606544, b 2.2756005683762908, iteration 41, cost 0.1073395295828815\n",
      "m 2.213735385878407, b 2.306887840824943, iteration 42, cost 0.10039058653754176\n",
      "m 2.170254943136438, b 2.315192801071317, iteration 43, cost 0.09405986334903649\n",
      "m 2.1993136987020745, b 2.3430395801944157, iteration 44, cost 0.08826423771269985\n",
      "m 2.1638625904931037, b 2.3524826719863134, iteration 45, cost 0.08293518155053264\n",
      "m 2.1862727486718105, b 2.3774314010318136, iteration 46, cost 0.07801592372722821\n",
      "m 2.1572656385141533, b 2.3876314575042543, iteration 47, cost 0.07345918129710392\n",
      "m 2.1744150151272015, b 2.4101229178167802, iteration 48, cost 0.06922534441882239\n",
      "m 2.150585587951272, b 2.4207840437050385, iteration 49, cost 0.06528102333197575\n",
      "m 2.1635786121786147, b 2.441177514495622, iteration 50, cost 0.06159788433500965\n",
      "m 2.1439150477863547, b 2.4520713783305874, iteration 51, cost 0.05815171649232756\n",
      "m 2.153630302083688, b 2.470660734860243, iteration 52, cost 0.054921682590988646\n",
      "m 2.137323817683481, b 2.4816124722824338, iteration 53, cost 0.05188971727120564\n",
      "m 2.1444599118649865, b 2.4986390442291735, iteration 54, cost 0.04904004275389065\n",
      "m 2.1308637257526066, b 2.509516039457312, iteration 55, cost 0.04635877856867898\n",
      "m 2.1359758694885094, b 2.525178884782891, iteration 56, cost 0.04383362645496491\n",
      "m 2.124572474492945, b 2.535881845863144, iteration 57, cost 0.04145361541183607\n",
      "m 2.128101633371053, b 2.5503459627684273, iteration 58, cost 0.03920889490609494\n",
      "m 2.118476696509155, b 2.5608018247073736, iteration 59, cost 0.03709056666678448\n",
      "m 2.120772834793503, b 2.5742047184297996, iteration 60, cost 0.03509054742420437\n",
      "m 2.112594380710634, b 2.5843610027801502, iteration 61, cost 0.03320145649050715\n",
      "m 2.1139349893254455, b 2.5968179395942217, iteration 62, cost 0.03141652330669783\n",
      "m 2.1069367971074353, b 2.606638274382932, iteration 63, cost 0.0297295110602709\n",
      "m 2.1075416624945413, b 2.618246487870094, iteration 64, cost 0.0281346532591438\n",
      "m 2.1015100223265035, b 2.6277070518134993, iteration 65, cost 0.02662660077102551\n",
      "m 2.101552998161378, b 2.6385491128066176, iteration 66, cost 0.025200377334927134\n",
      "m 2.096316147250177, b 2.6476358156400974, iteration 67, cost 0.023851341948628327\n",
      "m 2.095934536582619, b 2.657782334457597, iteration 68, cost 0.022575156852933542\n",
      "m 2.0913542316575633, b 2.6664885833847243, iteration 69, cost 0.021367760086655644\n",
      "m 2.090656263915584, b 2.676000378847538, iteration 70, cost 0.020225341788425083\n",
      "m 2.0866210575773376, b 2.6843253115524512, iteration 71, cost 0.019144323582910155\n",
      "m 2.0856918466960472, b 2.693255154066937, iteration 72, cost 0.018121340518098442\n",
      "m 2.082111722558874, b 2.7012022430021245, iteration 73, cost 0.017153225123473996\n",
      "m 2.0810180142142363, b 2.709596257293525, iteration 74, cost 0.01623699324146153\n",
      "m 2.077820105696288, b 2.717172209303728, iteration 75, cost 0.015369831350564987\n",
      "m 2.0766140592050317, b 2.7250710050809133, iteration 76, cost 0.014549085151541019\n",
      "m 2.0737392325653374, b 2.732284895849552, iteration 77, cost 0.013772249230347736\n",
      "m 2.0724614332425584, b 2.7397244808822614, iteration 78, cost 0.013036957645638886\n",
      "m 2.0698615599121704, b 2.7465870759846718, iteration 79, cost 0.012340975315898037\n",
      "m 2.0685434179941087, b 2.7535995950692826, iteration 80, cost 0.011682190103287127\n",
      "m 2.066179196691222, b 2.760122819221025, iteration 81, cost 0.011058605508984853\n",
      "m 2.064844857288579, b 2.7667371537338745, iteration 82, cost 0.010468333909073289\n",
      "m 2.0626840746684203, b 2.7729336776379365, iteration 83, cost 0.009909590271584152\n",
      "m 2.061351937985791, b 2.7791759333750248, iteration 84, cost 0.009380686304666458\n",
      "m 2.0593680791107873, b 2.785058853801841, iteration 85, cost 0.00888002499345325\n",
      "m 2.0580520100509183, b 2.7909527592203687, iteration 86, cost 0.00840609548939642\n",
      "m 2.056223147935525, b 2.7965353529206687, iteration 87, cost 0.007957468320912865\n",
      "m 2.05493343816708, b 2.8021025854443096, iteration 88, cost 0.007532790898352296\n",
      "m 2.0532413459797505, b 2.8073981214530215, iteration 89, cost 0.007130783289727114\n",
      "m 2.0519854787579397, b 2.812658575950258, iteration 90, cost 0.0067502342464980354\n",
      "m 2.050414919687842, b 2.8176801739944057, iteration 91, cost 0.006389997461079277\n",
      "m 2.0491981775199255, b 2.8226521847051367, iteration 92, cost 0.006048988039717134\n",
      "m 2.047736336426391, b 2.8274127099427506, iteration 93, cost 0.005726179176078216\n",
      "m 2.0465622835434223, b 2.8321132348672426, iteration 94, cost 0.005420599012302664\n",
      "m 2.045198311770722, b 2.836625221187641, iteration 95, cost 0.005131327675503935\n",
      "m 2.0440691768841837, b 2.8410699961476715, iteration 96, cost 0.0048574944787420265\n",
      "m 2.042793827417138, b 2.845345591859636, iteration 97, cost 0.004598275276411798\n",
      "m 2.0417108070703494, b 2.8495492600018677, iteration 98, cost 0.004352889964781892\n",
      "m 2.0405161418256377, b 2.8536001910078013, iteration 99, cost 0.004120600119124239\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(x,y):\n",
    "    # start with some values of m and b\n",
    "    m_curr = b_curr = 0\n",
    "    iterations = 100\n",
    "    n = len(x)\n",
    "    learning_rate = 0.08\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "        \n",
    "        cost = (1/n) * sum([val**2 for val in y-y_predicted])\n",
    "        \n",
    "        # m derivative\n",
    "        md = -(2/n) * sum(x*(y - y_predicted))\n",
    "        \n",
    "        # b derivative\n",
    "        bd = -(2/n) * sum(y - y_predicted)\n",
    "        \n",
    "        m_curr = m_curr - learning_rate * md\n",
    "        \n",
    "        b_curr = b_curr - learning_rate * bd\n",
    "        \n",
    "        print(f\"m {m_curr}, b {b_curr}, iteration {i}, cost {cost}\")\n",
    "\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = np.array([5,7,9,11,13])\n",
    "\n",
    "gradient_descent(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
